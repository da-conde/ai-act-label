# tabs/tab_ai_act_mapping.py  (ONLINE / Streamlit Cloud Variante â€“ basiert auf deinem lokalen Code)

import streamlit as st
import graphviz
import pandas as pd
from pathlib import Path


# ----------------------------------------------------
# Storage (ONLINE)
# ----------------------------------------------------
# Streamlit Cloud: nutze persistentes Volume, falls vorhanden.
# Fallback: lokales Projektverzeichnis.
try:
    _BASE_DIR = Path(st.secrets.get("STORAGE_DIR", "."))
except Exception:
    _BASE_DIR = Path(".")

DATA_DIR = _BASE_DIR / "data"
MAPPING_FILE = DATA_DIR / "ai_act_mapping.csv"


# ----------------------------------------------------
# Hilfsfunktionen
# ----------------------------------------------------

def ensure_data_dir():
    DATA_DIR.mkdir(parents=True, exist_ok=True)


def default_mapping_df() -> pd.DataFrame:
    """
    Default-Schema: EXACTLY ONE ROW PER CATEGORY (fÃ¼r Mindmap: 1 Pfeil pro Kategorie)

    Kategorien (online, v2):
      1) Data Provenance
      2) Data Composition
      3) Obtained From
      4) Data Preparation and Processing
      5) Bias and Fairness Disclosure
      6) Annahmen Ã¼ber den Datensatz
    """
    rows = [
        {
            "pillar": "Art. 10(2)(b)",
            "category": "Data Provenance",
            "detail": "Quelle/Herkunft des Datensatzes (inkl. direkter VorgÃ¤nger bei Derived Datasets).",
        },
        {
            "pillar": "Art. 10(2)",
            "category": "Data Composition",
            "detail": "Zusammensetzung/Typ der Daten (z. B. real-world vs. synthetic; selbst erhoben).",
        },
        {
            "pillar": "Annex IV 2(d)",
            "category": "Obtained From",
            "detail": "Wie die Daten bezogen/erhoben/selektiert wurden (z. B. Scraping, Sensor, API, Sampling).",
        },
        {
            "pillar": "Art. 10(2)(c)",
            "category": "Data Preparation and Processing",
            "detail": "Welche Verarbeitungsschritte ab Rohdaten erfolgt sind (oder explizit: keine).",
        },
        {
            "pillar": "Art. 10(2)(f)(g)",
            "category": "Bias and Fairness Disclosure",
            "detail": "Bias/Fairness/RepresentativitÃ¤t: bekannte Risiken oder durchgefÃ¼hrte Analysen.",
        },
        {
            "pillar": "Art. 10(2)(d)",
            "category": "Annahmen Ã¼ber den Datensatz",
            "detail": "Sachebene & Kontext: was die Daten darstellen/messen sollen (nicht nur technische Specs).",
        },
    ]
    return pd.DataFrame(rows, columns=["pillar", "category", "detail"])


def load_mapping_df() -> pd.DataFrame:
    """
    LÃ¤dt die Mapping-Tabelle.

    Zielzustand:
      - EXACTLY ONE ROW PER CATEGORY
      - Falls Datei fehlt oder Kategorien nicht passen -> Reset auf Default.
      - Falls Datei existiert, aber Kategorien mehrfach vorkommen -> auf 1 Row pro Kategorie reduzieren
        (erste nicht-leere Detail-Zeile wird genommen).
    """
    ensure_data_dir()

    wanted_cats = [
        "Data Provenance",
        "Data Composition",
        "Obtained From",
        "Data Preparation and Processing",
        "Bias and Fairness Disclosure",
        "Annahmen Ã¼ber den Datensatz",
    ]

    if MAPPING_FILE.exists():
        try:
            df = pd.read_csv(MAPPING_FILE)
        except Exception:
            df = pd.DataFrame()
    else:
        df = pd.DataFrame()

    # Wenn leer/inkonsistent -> Default
    if df.empty or "category" not in df.columns:
        df = default_mapping_df()
        df.to_csv(MAPPING_FILE, index=False)
        return df

    # Spalten absichern
    for col in ["pillar", "category", "detail"]:
        if col not in df.columns:
            df[col] = ""

    # trim
    df = df[["pillar", "category", "detail"]].copy()
    for col in ["pillar", "category", "detail"]:
        df[col] = df[col].fillna("").astype(str).str.strip()

    # Check: sind alle benÃ¶tigten Kategorien vorhanden?
    present = set(df["category"].dropna().unique().tolist())
    if not set(wanted_cats).issubset(present):
        df = default_mapping_df()
        df.to_csv(MAPPING_FILE, index=False)
        return df

    # REDUKTION: genau 1 Zeile pro Kategorie (erste sinnvolle Zeile gewinnt)
    reduced_rows = []
    for cat in wanted_cats:
        sub = df[df["category"] == cat].copy()

        # PrioritÃ¤t: Zeilen mit Detail > 0 Zeichen, sonst irgendwas
        sub_non_empty = sub[sub["detail"].astype(str).str.len() > 0]
        pick = sub_non_empty.iloc[0] if not sub_non_empty.empty else sub.iloc[0]

        reduced_rows.append(
            {
                "pillar": pick.get("pillar", "").strip(),
                "category": cat,
                "detail": pick.get("detail", "").strip(),
            }
        )

    df_reduced = pd.DataFrame(reduced_rows, columns=["pillar", "category", "detail"])

    # Datei aktualisieren (damit Mindmap kÃ¼nftig stabil 1 Pfeil/Kategorie ist)
    df_reduced.to_csv(MAPPING_FILE, index=False)
    return df_reduced


def save_mapping_df(df: pd.DataFrame):
    """
    Speichert NUR 1 Zeile pro Kategorie (erste gewinnt), damit die Mindmap
    pro Kategorie genau einen Detail-Knoten hat.
    """
    ensure_data_dir()

    wanted_cats = [
        "Data Provenance",
        "Data Composition",
        "Obtained From",
        "Data Preparation and Processing",
        "Bias and Fairness Disclosure",
        "Annahmen Ã¼ber den Datensatz",
    ]

    cleaned = df.copy()
    for col in ["pillar", "category", "detail"]:
        if col not in cleaned.columns:
            cleaned[col] = ""
        cleaned[col] = cleaned[col].fillna("").astype(str).str.strip()

    # nur Zeilen, die mindestens category haben
    cleaned = cleaned[cleaned["category"].astype(str).str.len() > 0]

    # genau 1 Zeile pro wanted category, in fester Reihenfolge
    reduced_rows = []
    for cat in wanted_cats:
        sub = cleaned[cleaned["category"] == cat]
        if sub.empty:
            # falls Nutzer Kategorie gelÃ¶scht hat -> Default-Zeile wieder herstellen
            default_row = default_mapping_df()
            d = default_row[default_row["category"] == cat].iloc[0].to_dict()
            reduced_rows.append(d)
            continue

        sub_non_empty = sub[sub["detail"].astype(str).str.len() > 0]
        pick = sub_non_empty.iloc[0] if not sub_non_empty.empty else sub.iloc[0]
        reduced_rows.append(
            {
                "pillar": pick.get("pillar", "").strip(),
                "category": cat,
                "detail": pick.get("detail", "").strip(),
            }
        )

    out = pd.DataFrame(reduced_rows, columns=["pillar", "category", "detail"])
    out.to_csv(MAPPING_FILE, index=False)


def build_graph_from_df(df: pd.DataFrame) -> graphviz.Digraph:
    """
    Mindmap: pro Kategorie genau ein Detail-Knoten.

      AI Act
        â†’ Kategorie (mit Pillar-Suffix)
             â†’ Detail (1 kurzer Kasten)
    """
    dot = graphviz.Digraph(comment="AI Act Transparency Mapping")
    dot.attr(rankdir="TB")
    dot.attr("node", shape="box", style="rounded,filled", fillcolor="#F5F5F5")

    root_id = "root"
    root_label = "AI Act\n(Transparenz- & Datenpflichten)"
    dot.node(root_id, root_label)

    node_counter = 0

    def new_id():
        nonlocal node_counter
        node_counter += 1
        return f"n{node_counter}"

    df_clean = df.copy()
    for col in ["pillar", "category", "detail"]:
        df_clean[col] = df_clean[col].fillna("").astype(str).str.strip()

    if df_clean.empty:
        return dot

    # 1) Kategorie-Knoten
    category_nodes = {}
    for _, row in df_clean.iterrows():
        cat = row["category"]
        pil = row["pillar"]
        if not cat:
            continue
        if cat in category_nodes:
            continue  # Sicherheit: keine Duplikate im Graph
        c_id = new_id()
        suffix = f"\n({pil})" if pil else ""
        dot.node(c_id, f"{cat}{suffix}")
        dot.edge(root_id, c_id)
        category_nodes[cat] = c_id

    # 2) Genau EIN Detail-Knoten pro Kategorie
    for _, row in df_clean.iterrows():
        cat = row["category"]
        detail = row["detail"]
        if not cat or cat not in category_nodes:
            continue
        c_id = category_nodes[cat]
        d_id = new_id()
        dot.node(d_id, detail, shape="note", fillcolor="#FFFFFF")
        dot.edge(c_id, d_id)

    return dot


# ----------------------------------------------------
# Render-Funktion
# ----------------------------------------------------

def render():
    st.subheader("ğŸ“š AI Act Mapping â€“ Transparenzanforderungen (Online)")

    st.write(
        """
        Hier strukturierst du die **transparenzrelevanten Pflichten des AI Act**
        und leitest daraus deine operativen Kategorien ab.

        **Visualisierung:**
        *AI Act â†’ Kategorie â†’ 1 kurzer Detail-Kasten*

        Kategorien (online, v2):
        1. **Data Provenance**
        2. **Data Composition**
        3. **Obtained From**
        4. **Data Preparation and Processing**
        5. **Bias and Fairness Disclosure**
        6. **Annahmen Ã¼ber den Datensatz**
        """
    )

    # 1) Mapping laden (inkl. Reduktion auf 1 Row/Kategorie)
    df = load_mapping_df()

    # 2) Mindmap anzeigen
    st.markdown("### ğŸŒ³ Aktuelle AI Act Mindmap (1 Detail pro Kategorie)")
    try:
        dot = build_graph_from_df(df)
        st.graphviz_chart(dot, use_container_width=True)
    except Exception as e:
        st.error(f"Mindmap-Fehler: {e}")

    st.markdown("---")

    # 3) Editor: exakt 6 Zeilen (1 pro Kategorie) anzeigen/bearbeiten
    st.markdown("### âœï¸ AI Act Mapping Tabelle bearbeiten (1 Zeile pro Kategorie)")
    st.caption(
        "Hier bearbeitest du pro Kategorie genau **eine** kurze ErklÃ¤rung (Detail). "
        "Beim Speichern werden ggf. Duplikate wieder auf 1 Zeile pro Kategorie reduziert."
    )

    edited_df = st.data_editor(
        df,
        num_rows="fixed",
        use_container_width=True,
        key="ai_act_mapping_editor_one_row_per_cat_online",
    )

    if st.button("ğŸ’¾ Speichern & Mindmap aktualisieren", key="ai_act_mapping_save_online"):
        save_mapping_df(edited_df)
        st.success("Mapping gespeichert â€“ Mindmap wird aktualisiert.")

        if hasattr(st, "rerun"):
            st.rerun()
        elif hasattr(st, "experimental_rerun"):
            st.experimental_rerun()

    st.markdown("---")

    # 4) Kategorie-Guide (ausfÃ¼hrlicher, wie im Online-Tab)
    st.markdown("### ğŸ“– Kategorie-Guide fÃ¼r Labeling (ausfÃ¼hrlicher)")

    st.caption(
        "Ziel: Die folgenden Hinweise erklÃ¤ren **was** die Kategorie abdeckt, **wie** die Labels zu vergeben sind "
        "(âœ… ausreichend / â“ unklar / âŒ unzureichend) und geben **Mini-Beispiele**. "
        "Die Icons entsprechen dem Selector in den Labeling-Tabs."
    )

    # âœ… NUR DIESER EXPANDER IST ANGEPASST (Data Provenance wie von dir beschrieben)
    with st.expander("1ï¸âƒ£ Data Provenance (Art. 10(2)(b))", expanded=False):
        st.markdown(
            """
**Worum gehtâ€™s?**  
Nachvollziehbare **Herkunft/Quelle** der Daten: *Von wem / aus welcher Quelle stammen sie?*  
Wichtig: Es reicht **nicht**, einfach nur einen Datensatz **zu nennen** (z. B. *â€based on the EDALT datasetâ€œ*).  
Auch ein berÃ¼hmter Datensatz hat wiederum eine **eigene Quelle** â€“ und genau diese Herkunft/Urheberschaft muss erkennbar sein.  
Bei abgeleiteten DatensÃ¤tzen (Derived Datasets) zÃ¤hlt in eurer Logik insbesondere der **direkte VorgÃ¤nger-Datensatz** als Provenance-Stufe davor.

**âœ… Ausreichend**  
- Die Herkunft/Quelle ist **explizit** genannt und die **Urheberschaft erkennbar** (wer hat die Daten erzeugt/erhoben/gesammelt?).  
- Eigene Urheberschaft wird klar benannt (*â€wir haben â€¦ gesammelt/gescraped/erhobenâ€œ*).

**â“ Unklar**  
- Herkunft ist **angedeutet**, aber ohne Kontext nicht zweifelsfrei.  
  Beispiele: *â€scraped from Wikipediaâ€œ*, *â€sensor dataâ€œ* (wer/wo/wie genau?).  
- Dazu zÃ¤hlt auch: Es wird **nur ein Link** genannt (z. B. zu einem Repository), ohne im Text klar zu machen, **was** dort genau die Quelle ist  
  bzw. ohne eindeutige Provenance-Aussage (Link allein ist nicht automatisch â€explizite Herkunftâ€œ).

**âŒ Unzureichend**  
- **Keine** Angabe zur Herkunft/Quelle.  
- Oder es steht **nur der Name** eines Datensatzes, auf den Bezug genommen wird (z. B. *â€EDALT datasetâ€œ*),  
  aber man weiÃŸ danach immer noch nicht **woher** die Daten kommen oder **wie** man sie konkret findet/zuordnet.

**Mini-Beispiele**  
- âœ… *â€We scraped Wikipedia pages between 2022â€“2023 â€¦â€œ*  
- âœ… *â€Data was collected by our lab at â€¦ (institution) â€¦â€œ*  
- â“ *â€Wikipedia datasetâ€œ* / *â€Sensor logsâ€œ* (ohne Betreiber/Setup)  
- â“ *â€See repository: <link>â€œ* (nur Link, keine klare Provenance-Aussage)  
- âŒ *â€Based on the EDALT datasetâ€œ* (nur Name, keine Quelle/Herkunft)  
- âŒ README ohne Herkunftsangaben
"""
        )

    # Ø¨Ø§Ù‚ÙŠ Expander bleiben inhaltlich wie gehabt
    with st.expander("2ï¸âƒ£ Data Composition (Art. 10(2))", expanded=False):
        st.markdown(
            """
**Worum gehtâ€™s?**  
Klarheit Ã¼ber den **Typ / die Zusammensetzung** der Daten â€“ besonders wichtig fÃ¼r DatenqualitÃ¤t im Sinne von Art. 10:  
Sind es **Real-world** Daten, **Synthetic** Daten, oder **selbst erhobene** Daten?

**âœ… Ausreichend**  
- Explizite Benennung wie: *â€real-worldâ€œ*, *â€syntheticâ€œ* oder *â€collected by usâ€œ / â€self-collectedâ€œ*.

**âŒ Unzureichend**  
- Keine (oder nur implizite) Information, ob real/synthetisch/selbst erhoben.

**Mini-Beispiele**  
- âœ… *â€This dataset contains synthetic tabular records generated with â€¦â€œ*  
- âœ… *â€We collected the data via surveys â€¦â€œ*  
- âŒ Nur technische Specs, aber kein Hinweis auf real vs. synthetic
"""
        )

    with st.expander("3ï¸âƒ£ Obtained From (Annex IV 2(d) â€“ â€obtained and selectedâ€œ)", expanded=False):
        st.markdown(
            """
**Worum gehtâ€™s?**  
**Wie** wurden die Daten **bezogen/erhoben/selektiert**? (Mechanismus/Quelle des Bezugs)  
Das ist nahe an Provenance, aber mit Fokus auf den **Beschaffungs-/Erhebungsweg** (Scraping, API, Sensor, Sampling, â€¦).

**âœ… Ausreichend**  
- Es wird benannt, **wie** die Daten bezogen wurden.  
  Beispiele: *â€scraped from â€¦â€œ*, *â€collected via APIâ€œ*, *â€measured with sensor â€¦â€œ*, *â€sampled from â€¦â€œ*.

**âŒ Unzureichend**  
- Keine Angabe zum Erhebungs-/Bezugsweg.

**Mini-Beispiele**  
- âœ… *â€Collected via Twitter API (v2) using keywords â€¦â€œ*  
- âœ… *â€Scraped from Wikipedia using â€¦â€œ*  
- âŒ *â€Data from the webâ€œ* (zu vage, kein Mechanismus)
"""
        )

    with st.expander("4ï¸âƒ£ Data Preparation and Processing (Art. 10(2)(c))", expanded=False):
        st.markdown(
            """
**Worum gehtâ€™s?**  
Alle **Verarbeitungsschritte ab Existenz der Rohdaten**: Cleaning, Filtering, Normalisierung, Deduplication, Labeling, etc.  
Wichtig ist nicht nur â€dassâ€œ etwas gemacht wurde, sondern **wie** â€“ und **wie sich der resultierende Datensatz** vom Ausgangsdatensatz unterscheidet.

**âœ… Ausreichend**  
- Konkrete Beschreibung der Verarbeitung **und/oder** der resultierenden Unterschiede zum Ausgangsdatensatz.  
- Oder explizit: *â€no preprocessing was appliedâ€œ*.

**â“ Unklar**  
- Verarbeitung wird nur als Schlagwort genannt, ohne Qualifizierung/Methode/Konfiguration.  
  Beispiel: *â€outlier treatmentâ€œ* ohne Methode (z. B. Tukey fences) und ohne Parameter.

**âŒ Unzureichend**  
- Keine Angabe.

**Mini-Beispiele**  
- âœ… *â€We removed duplicates by hashing rows; dropped records with missing target; normalized features with z-score â€¦â€œ*  
- âœ… *â€No preprocessing was performed.â€œ*  
- â“ *â€Data was cleaned and outliers were treated.â€œ*  
- âŒ Keine Processing-Infos
"""
        )

    with st.expander("5ï¸âƒ£ Bias and Fairness Disclosure (Art. 10(2)(f)(g))", expanded=False):
        st.markdown(
            """
**Worum gehtâ€™s?**  
Angaben zu **Bias**, **Fairness**, **ReprÃ¤sentativitÃ¤t** und bekannten Verzerrungsrisiken â€“ oder Hinweise auf entsprechende Analysen.

**âœ… Ausreichend**  
- Benennung von Bias-/Fairness-relevanten Informationen (z. B. bekannte Verzerrungen, UnterreprÃ¤sentation, Sampling-Bias)  
  und/oder kurze Ergebnisse/Checks.

**âŒ Unzureichend**  
- Keine Angabe (keine Hinweise auf Bias/Fairness/RepresentativitÃ¤t).

**Mini-Beispiele**  
- âœ… *â€The dataset underrepresents age group 65+; results may not generalize.â€œ*  
- âœ… *â€We checked class imbalance and report distribution by gender/region â€¦â€œ*  
- âŒ Keine Bias-/Fairness-Infos
"""
        )

    with st.expander("6ï¸âƒ£ Annahmen Ã¼ber den Datensatz (Art. 10(2)(d))", expanded=False):
        st.markdown(
            """
**Worum gehtâ€™s?**  
Beschreibung auf **Sachebene & Kontext**: *Was stellen die Daten dar? Was sollen sie messen/abbilden?*  
Das ist mehr als technische Spezifikationen â€“ es geht um â€meaningâ€œ / intended measurement / intended use.

**âœ… Ausreichend**  
- Es ist erklÃ¤rt, welche Informationen in den Daten stecken bzw. was sie darstellen oder messen sollen  
  (Problem-/DomÃ¤nenbezug, Ziel, Kontext, intended use).

**âŒ Unzureichend**  
- Keine Angabe (z. B. leere README oder nur technische Specs ohne Bedeutung/ Kontext).

**Mini-Beispiele**  
- âœ… *â€Each record represents a hospital visit; label indicates 30-day readmission risk â€¦â€œ*  
- âœ… *â€Sensor measures vibration of machine X; goal is predictive maintenance â€¦â€œ*  
- âŒ *â€Columns: col1, col2 â€¦ dtype â€¦â€œ* ohne Kontext
"""
        )


def show_ai_act_mapping():
    render()